---
title: "Spam Classification"
author: "Abirami Sabbani"
date: "3/9/2022"
output:
  html_document:
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(latex2exp) 
library(ggforce) 
#library(e1071)
library(scales)
library(matrixStats)
library(caret)
library(MASS)
```


1) Standardized the columns so that they all have zero mean and unit variance.

```{r}
train = read.csv('spam-train.txt', header = FALSE)
```


```{r}
test = read.csv('spam-test.txt', header = FALSE)
```

```{r}
stan_train = scale(train)
```

```{r}
colMeans(stan_train)
```

```{r}
colVars(as.matrix(stan_train))
```



```{r}
stan_test = scale(test)
```

```{r}
colMeans(stan_test)
```


```{r}
colVars(stan_test)
```




2) Transformed the features using log(xij + 1).

```{r}
log_train = log(train + 1)
head(log_train)
```

```{r}
log_test = log(test + 1)
head(log_test)
```



3) Discretized each feature using I(xij > 0). 

```{r}
I_train = (train > 0 ) * 1
```


```{r}
I_test = (test > 0)*1
head(I_test)
```

**Visualization for original train and test data**

```{r}
boxplot(train)
```

```{r}
boxplot(test)
```

**Visualization for standardized train and test data**
```{r}
boxplot(stan_train)
```

```{r}
boxplot(stan_test)
```

**Visualization for log transformed train and test data**

```{r}
boxplot(log_train)
```

```{r}
boxplot(log_test)
```


**Visualization for discretized train and test data**

```{r}
boxplot(I_train)
```
```{r}
boxplot(I_test)
```


Since the train and test datasets have a different amount of data, the scale is different but the ratios are about the same. Also the log transformation feature shows a high variance for features 56 and 57, but it is not as noticeable when the feature is standardized.


```{r}
stan_train = as.data.frame(stan_train)
log_train = as.data.frame(log_train)
I_train = as.data.frame(I_train)
```


```{r}
stan_train$V58 <- train$V58
log_train$V58 <- train$V58
I_train$V58 <- train$V58
```



```{r}
test = as.data.frame(test)
stan_test = as.data.frame(stan_test)
log_test = as.data.frame(log_test)
I_test = as.data.frame(I_test)
```


```{r}
stan_test$V58 <- test$V58
log_test$V58 <- test$V58
I_test$V58 <- test$V58
stan_train$V58 <- train$V58
log_train$V58 <- train$V58
I_train$V58 <- train$V58
```

4) 
**Linear Regression on original train and test data**

```{r}
train = as.data.frame(train)
```

```{r}
test = as.data.frame(test)
```


```{r}
lr_train <- glm(V58 ~ ., data = train, family = "binomial")
summary(lr_train)
```
From the summary, the result indicates that features: 4,5, 7, 8, 9, 11, 16, 17, 19, 20, 21, 23, 25, 27, 42, 44, 45, 46, 47, 49, 52, 52, 55, 56,
and 57 are statistically significant because their p-values are less then 0.05

```{r}
pred_train <- (predict(lr_train, train) > 0) * 1
pred_test <- (predict(lr_train, test) > 0) * 1
```

```{r}
cm_lr_train = confusionMatrix(as.factor(pred_train), as.factor(train$V58), positive = "1")
cm_lr_train
```
The accuracy is 92.83% for the classification error of the Logistic Regression of train data.


```{r}
cm_lr_test = confusionMatrix(as.factor(pred_test), as.factor(test$V58), positive = "1")
cm_lr_test
```
The accuracy is 92.7% for the classification error of the Logistic Regression of test data.

**Linear Regression on Standardized Train and Test Data**

```{r}
lr_stan_train <- glm(V58 ~ ., data = stan_train, family = "binomial")
summary(lr_stan_train)
```
The features: 4, 5, 7, 8, 9, 11, 16, 17, 19, 20, 21, 23, 25, 27, 42, 44, 45, 46, 47, 49, 52, 53, 55, 56, 57 are statistically significant 

```{r}
pred_stdtrain <- (predict(lr_stan_train, train) > 0) * 1
pred_stdtest <- (predict(lr_stan_train, test) > 0) * 1
```

```{r}
cm_lr_stan_train = confusionMatrix(as.factor(pred_stdtrain), as.factor(train$V58), positive = "1")
cm_lr_stan_train
```
The accuracy is 54.16% for the classification error of the Logistic Regression of standardized train data.


```{r}
cm_lr_stan_test = confusionMatrix(as.factor(pred_stdtest), as.factor(test$V58), positive = "1")
cm_lr_stan_test
```
The accuracy is 55.22% for the classification error of the Logistic Regression of standardized test data.

**Linear Regression on Log Transformation train and test data**

```{r}
lr_log_train <- glm(V58 ~ ., data = log_train, family = "binomial")
summary(lr_log_train)
```
The features: 5, 7, 8, 11, 13, 16, 17, 20, 21, 23, 24, 25, 27, 28, 33, 35, 37, 42, 43, 45, 46, 49, 52, 53, 57 are statistically significant

```{r}
pred_logtrain <- (predict(lr_log_train, train) > 0) * 1
pred_logtest <- (predict(lr_log_train, test) > 0) * 1
```

```{r}
cm_lr_log_train = confusionMatrix(as.factor(pred_logtrain), as.factor(train$V58), positive = "1")
cm_lr_log_train
```
The accuracy is 53.47% for the classification error of the Logistic Regression of log transformation of train data.


```{r}
cm_lr_log_test = confusionMatrix(as.factor(pred_logtest), as.factor(test$V58), positive = "1")
cm_lr_log_test
```
The accuracy is 54.11% for the classification error of the Logistic Regression of log transformation of test data.

**Logistic Regression on Discretized train and test data**

```{r}
lr_I_train <- glm(V58 ~ ., data = I_train, family = "binomial")
summary(lr_I_train)
```

The features: 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 37, 42, 43, 44, 45, 46, 48, 52, 53, 54 are statistically significant. Also have features 55, 56, 57 as NA in the summary function because these features are singularities, meaning that 
their respective columns are either all 0s or all 1s so cannot get a p-value from it.

```{r}
pred_I_train <- (predict(lr_I_train, train) > 0) * 1
pred_I_test <- (predict(lr_I_train, test) > 0) * 1
```

```{r}
cm_lr_I_train = confusionMatrix(as.factor(pred_I_train), as.factor(train$V58), positive = "1")
cm_lr_I_train
```

The accuracy is 90.19% for the classification error of the Logistic Regression of discretize transformation of train data.

```{r}
cm_lr_I_test = confusionMatrix(as.factor(pred_I_test), as.factor(test$V58), positive = "1")
cm_lr_I_test
```
The accuracy is 89.7% for the classification error of the Logistic Regression of discretize transformation of test data.

```{r}
cm_lr_train$overall['Accuracy']
cm_lr_test$overall['Accuracy']
cm_lr_stan_train$overall['Accuracy']
cm_lr_stan_test$overall['Accuracy']
cm_lr_log_train$overall['Accuracy']
cm_lr_log_test$overall['Accuracy']
cm_lr_I_train$overall['Accuracy']
cm_lr_I_test$overall['Accuracy']
```


```{r}
accuracy.lr.table <- matrix( c(cm_lr_train$overall['Accuracy'], cm_lr_test$overall['Accuracy'], cm_lr_stan_train$overall['Accuracy'], cm_lr_stan_test$overall['Accuracy'], cm_lr_log_train$overall['Accuracy'], cm_lr_log_test$overall['Accuracy'], cm_lr_I_train$overall['Accuracy'], cm_lr_I_test$overall['Accuracy']), ncol=4)

accuracy.lr.table
```

```{r}
colnames(accuracy.lr.table) <- c("lr original", "lr standardized", "lr log", "lr I")
rownames(accuracy.lr.table) <- c("train", "test")

accuracy.lr.table
```
The classification accuracies are in the table above for the training and testing datasets.

5) Applying both linear and quadratic discriminant analysis methods to the standardized data, and the log transformed data. 


**LDA for standardized train and test Data**
```{r}
lda_train_stan <- lda(V58 ~ ., data = stan_train)
qda_train_stan <- qda(V58 ~ ., data = stan_train)
```

```{r}

lda_predict_train_stan <- predict(lda_train_stan, stan_train)$class
lda_predict_test_stan <- predict(lda_train_stan, stan_test)$class
```

```{r}
cm_lda_stan_test = confusionMatrix(as.factor(lda_predict_test_stan), as.factor(stan_test$V58), positive = "1")
cm_lda_stan_test
```
The accuracy is 89.7% for the classification error of the lda standardized test data.

```{r}
cm_lda_stan_train = confusionMatrix(as.factor(lda_predict_train_stan), as.factor(stan_train$V58), positive = "1")
cm_lda_stan_train
```
The accuracy is 89.83% for the classification error of the lda standardized train data.


**QDA for standardized train and test data**

```{r}
qda_predict_train_stan <- predict(qda_train_stan, stan_train)$class
qda_predict_test_stan <- predict(qda_train_stan, stan_test)$class
```

```{r}
cm_qda_stan_test = confusionMatrix(as.factor(qda_predict_test_stan), as.factor(stan_test$V58), positive = "1")
cm_qda_stan_test
```

The accuracy is 82.53% for the classification error of the qda standardized test data.


```{r}
cm_qda_stan_train = confusionMatrix(as.factor(qda_predict_train_stan), as.factor(stan_train$V58), positive = "1")
cm_qda_stan_train
```

The accuracy is 82.13% for the classification error of the qda standardized train data.


**LDA for log transformation train and test data**

```{r}
lda_train_log <- lda(V58 ~ ., data = log_train)
qda_train_log <- qda(V58 ~ ., data = log_train)
```



```{r}
lda_predict_train_log <- predict(lda_train_log, log_train)$class
lda_predict_test_log <- predict(lda_train_log, log_test)$class
```

```{r}
cm_lda_log_test = confusionMatrix(as.factor(lda_predict_test_log), as.factor(log_test$V58), positive = "1")
cm_lda_log_test
```


The accuracy is 93.48% for the classification error of the lda log test data.



```{r}
cm_lda_log_train = confusionMatrix(as.factor(lda_predict_train_log), as.factor(log_train$V58), positive = "1")
cm_lda_log_train
```
The accuracy is 93.48% for the classification error of the lda log train data.



**QDA for log transformation train and test data**


```{r}
qda_predict_train_log <- predict(qda_train_log, log_train)$class
qda_predict_test_log <- predict(qda_train_log, log_test)$class
```

```{r}
cm_qda_log_test = confusionMatrix(as.factor(qda_predict_test_log), as.factor(log_test$V58), positive = "1")
cm_qda_log_test
```

The accuracy is 84.29% for the classification error of the qda log test data.

```{r}
cm_qda_log_train = confusionMatrix(as.factor(qda_predict_train_log), as.factor(log_train$V58), positive = "1")
cm_qda_log_train
```
The accuracy is 84.12% for the classification error of the qda log train data.


```{r}
cm_lda_stan_train$overall['Accuracy']
cm_lda_stan_test$overall['Accuracy']
cm_lda_log_train$overall['Accuracy']
cm_lda_log_test$overall['Accuracy']
cm_qda_stan_train$overall['Accuracy']
cm_qda_stan_test$overall['Accuracy']
cm_qda_log_train$overall['Accuracy']
cm_qda_log_test$overall['Accuracy']
```


```{r}
accuracy.da.table <- matrix( c(cm_lda_stan_train$overall['Accuracy'], cm_lda_stan_test$overall['Accuracy'], cm_lda_log_train$overall['Accuracy'], cm_lda_log_test$overall['Accuracy'], cm_qda_stan_train$overall['Accuracy'], cm_qda_stan_test$overall['Accuracy'], cm_qda_log_train$overall['Accuracy'], cm_qda_log_test$overall['Accuracy']), ncol=4)

accuracy.da.table
```


```{r}
colnames(accuracy.da.table) <- c("lda stan", "lda log", "qda stan", "qda log")
rownames(accuracy.da.table) <- c("train", "test")

accuracy.da.table
```
For all of the above, LDA and QDA for standardized and log transformed data on both test and train data sets, the LDA performed better than the QDA.

6)
Applying linear and nonlinear support vector machine classifiers to each version of the data.


```{r}
library(e1071)
```


**Linear SVM for original data**

```{r}
new_train = train
new_train$V58 = as.factor(new_train$V58)
new_test = test
new_test$V58 = as.factor(new_test$V58)
```

```{r}
tune.linear = tune(svm, V58 ~ ., data = new_train, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10)), validation.x = new_test)
```

```{r}
summary(tune.linear)
```



```{r}
train_svm <- svm(V58 ~ ., kernel = "linear", data=new_train, cost=10)
```

```{r}
plot(train_svm, new_train, formula = V2 ~ V4)
```

```{r}
svm_predict_train <- predict(train_svm,new_train)
```

```{r}
cm_linear_train <- confusionMatrix(as.factor(svm_predict_train), as.factor(new_train$V58), positive = "1")
cm_linear_train
```
The accuracy is 93.74% for the linear svm classifier of the train data.

```{r}
svm_predict_test <- predict(train_svm,new_test)
```

```{r}
cm_linear_test <- confusionMatrix(as.factor(svm_predict_test), as.factor(new_test$V58), positive = "1")
cm_linear_test
```
The accuracy is 93.42% for the linear svm classifier of the test data.

**Linear SVM for standardized data**

```{r}
new_stan_train = stan_train
new_stan_train$V58 = as.factor(new_stan_train$V58)
```


```{r}
new_stan_test = stan_test
new_stan_test$V58 = as.factor(new_stan_test$V58)
```

```{r}
tune.linear = tune(svm, V58 ~ ., data = new_stan_train, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10)), validation.x = new_stan_test)
```

```{r}
summary(tune.linear)
```

```{r}
stan_train_svm <- svm(V58 ~ ., kernel = "linear", data=new_stan_train, cost=0.1)
```

```{r}
plot(stan_train_svm, new_stan_train, formula = V2 ~ V4)
```


```{r}
svm_predict_train_stan <- predict(stan_train_svm,new_stan_train)
```

```{r}
cm_linear_stan_train <- confusionMatrix(as.factor(svm_predict_train_stan), as.factor(new_stan_train$V58), positive = "1")
cm_linear_stan_train
```

The accuracy is 92.73% for the linear svm classifier of the standardized train data.

```{r}
svm_predict_test_stan <- predict(stan_train_svm,new_stan_test)
```

```{r}
cm_linear_stan_test <- confusionMatrix(as.factor(svm_predict_test_stan), as.factor(new_stan_test$V58), positive = "1")
cm_linear_stan_test
```

The accuracy is 93.22% for the linear svm classifier of the standardized test data.

**Linear SVM for log transformed data**


```{r}
new_log_train = log_train
new_log_train$V58 = as.factor(new_log_train$V58)
```


```{r}
new_log_test = log_test
new_log_test$V58 = as.factor(new_log_test$V58)
```


```{r}
tune.linear = tune(svm, V58 ~ ., data = new_log_train, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10)), validation.x = new_log_test)
```

```{r}
summary(tune.linear)
```


```{r}
log_train_svm <- svm(V58 ~ ., kernel = "linear", data=new_log_train, cost=0.01)
```

```{r}
plot(log_train_svm, new_log_train, formula = V2 ~ V4)
```


```{r}
svm_predict_train_log <- predict(log_train_svm,new_log_train)
```

```{r}
cm_linear_log_train <- confusionMatrix(as.factor(svm_predict_train_log), as.factor(new_log_train$V58), positive = "1")
cm_linear_log_train
```


The linear svm accuracy for the log transformed train data is 94.10%.


```{r}
svm_predict_test_log <- predict(log_train_svm,new_log_test)
```

```{r}
cm_linear_log_test <- confusionMatrix(as.factor(svm_predict_test_log), as.factor(new_log_test$V58), positive = "1")
cm_linear_log_test
```


The linear svm accuracy for the log transformed test data is 94.20%.


**Linear SVM for Discretized I data**


```{r}
new_I_train = I_train
new_I_train$V58 = as.factor(new_I_train$V58)
```


```{r}
new_I_test = I_test
new_I_test$V58 = as.factor(new_I_test$V58)
```


```{r}
tune.linear = tune(svm, V58 ~ ., data = new_I_train, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10)), validation.x = new_I_test)
```


```{r}
summary(tune.linear)
```



```{r}
I_train_svm <- svm(V58 ~ ., kernel = "linear", data=new_I_train, cost=5)
```



```{r}
plot(I_train_svm, new_I_train, formula = V3 ~ V4)  
```


```{r}
svm_predict_train_I <- predict(I_train_svm,new_I_train)
```

```{r}
cm_linear_I_train <- confusionMatrix(as.factor(svm_predict_train_I), as.factor(new_I_train$V58), positive = "1")
cm_linear_I_train
```

The linear SVM accuracy for the discretized train data is 94.13%.


```{r}
svm_predict_test_I <- predict(I_train_svm,new_I_test)
```

```{r}
cm_linear_I_test <- confusionMatrix(as.factor(svm_predict_test_I), as.factor(new_I_test$V58), positive = "1")
cm_linear_I_test
```
The linear SVM accuracy for the discretized test data is 92.44%.


**Gaussian SVM for original data**

```{r}
tune.gaussian = tune(svm, V58 ~ ., data = new_train, kernel = "radial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      gamma = c(0.001, 0.01, 0.1, 1)), validation.x = new_test)
```


```{r}
summary(tune.gaussian)
```



```{r}
train_svm <- svm(V58 ~ ., kernel = "radial", data=new_train, cost=10, gamma =0.01)
```

```{r}
plot(train_svm, new_train, formula = V2 ~ V4)
```

```{r}
svm_predict_train <- predict(train_svm,new_train)
```

```{r}
cm_gaussian_train <- confusionMatrix(as.factor(svm_predict_train), as.factor(new_train$V58), positive = "1")
cm_gaussian_train
```
The accuracy is 96.28% for the guassian svm classifier of the train data.

```{r}
svm_predict_test <- predict(train_svm,new_test)
```

```{r}
cm_gaussian_test <- confusionMatrix(as.factor(svm_predict_test), as.factor(new_test$V58), positive = "1")
cm_gaussian_test
```
The accuracy is 94.52% for the Guassian svm classifier of the test data.


**Gaussian SVM for standardized data**

```{r}
tune.gaussian = tune(svm, V58 ~ ., data = new_stan_train, kernel = "radial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      gamma = c(0.001, 0.01, 0.1, 1)), validation.x = new_stan_test)
```


```{r}
summary(tune.gaussian)
```


```{r}
stan_train_svm <- svm(V58 ~ ., kernel = "radial", data=new_stan_train, cost=10, gamma = 0.01)
```

```{r}
plot(stan_train_svm, new_stan_train, formula = V2 ~ V4)
```


```{r}
svm_predict_train_stan <- predict(stan_train_svm,new_stan_train)
```

```{r}
cm_gaussian_stan_train <- confusionMatrix(as.factor(svm_predict_train_stan), as.factor(new_stan_train$V58), positive = "1")
cm_gaussian_stan_train
```

The accuracy is 96.28% for the guassian svm classifier of the standardized train data.

```{r}
svm_predict_test_stan <- predict(stan_train_svm,new_stan_test)
```

```{r}
cm_gaussian_stan_test <- confusionMatrix(as.factor(svm_predict_test_stan), as.factor(new_stan_test$V58), positive = "1")
cm_gaussian_stan_test
```

The accuracy is 94.13% for the gaussian svm classifier of the standardized test data.


**Gaussian SVM for log transformed data**


```{r}
tune.gaussian = tune(svm, V58 ~ ., data = new_log_train, kernel = "radial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      gamma = c(0.001, 0.01, 0.1, 1)), validation.x = new_log_test)
```


```{r}
summary(tune.gaussian)
```


```{r}
log_train_svm <- svm(V58 ~ ., kernel = "radial", data=new_log_train, cost=10, gamma = 0.01)
```

```{r}
plot(log_train_svm, new_log_train, formula = V2 ~ V4)
```


```{r}
svm_predict_train_log <- predict(log_train_svm,new_log_train)
```

```{r}
cm_gaussian_log_train <- confusionMatrix(as.factor(svm_predict_train_log), as.factor(new_log_train$V58), positive = "1")
cm_gaussian_log_train
```

The accuracy is 97.78% for the gaussian svm classifier of the log transformed train data.

```{r}
svm_predict_test_log <- predict(log_train_svm,new_log_test)
```

```{r}
cm_gaussian_log_test <- confusionMatrix(as.factor(svm_predict_test_log), as.factor(new_log_test$V58), positive = "1")
cm_gaussian_log_test
```

The accuracy is 96.22% for the gaussian svm classifier of the log transform test data.


**Gaussian kernel for discretized train and test data**


```{r}
tune.gaussian = tune(svm, V58 ~ ., data = new_I_train, kernel = "radial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      gamma = c(0.001, 0.01, 0.1, 1)), validation.x = new_I_test)
```


```{r}
summary(tune.gaussian)
```


```{r}
I_train_svm <- svm(V58 ~ ., kernel = "radial", data=new_I_train, cost=10, gamma = 0.1)
```

```{r}
plot(I_train_svm, new_I_train, formula = V4 ~ V7)
```


```{r}
svm_predict_train_I <- predict(I_train_svm,new_I_train)
```

```{r}
cm_gaussian_I_train <- confusionMatrix(as.factor(svm_predict_train_I), as.factor(new_I_train$V58), positive = "1")
cm_gaussian_I_train
```

The accuracy is 98.01% for the gaussian svm classifier of the discretized train data.

```{r}
svm_predict_test_I <- predict(I_train_svm,new_I_test)
```

```{r}
cm_gaussian_I_test <- confusionMatrix(as.factor(svm_predict_test_I), as.factor(new_I_test$V58), positive = "1")
cm_gaussian_I_test
```

The accuracy is 95.11% for the gaussian svm classifier of the discretized test data.


**Polynomial SVM for original data**
```{r}
tune.polynomial = tune(svm, V58 ~ ., data = new_train, kernel = "polynomial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      degree = c(2, 3, 4, 5)), validation.x = new_test)
```

```{r}
summary(tune.polynomial)
```


```{r}
train_svm <- svm(V58 ~ ., kernel = "polynomial", data=new_train, cost=10, degree = 2)
```

```{r}
plot(train_svm, new_train, formula = V2 ~ V4)
```

```{r}
svm_predict_train <- predict(train_svm,new_train)
```

```{r}
cm_poly_train <- confusionMatrix(as.factor(svm_predict_train), as.factor(new_train$V58), positive = "1")
cm_poly_train
```
The accuracy is 95.47% for the polynomial svm classifier of the train data.

```{r}
svm_predict_test <- predict(train_svm,new_test)
```

```{r}
cm_poly_test <- confusionMatrix(as.factor(svm_predict_test), as.factor(new_test$V58), positive = "1")
cm_poly_test
```
The accuracy is 92.24% for the polynomial svm classifier of the test data.

**Polynomial SVM for standardized data**

```{r}
tune.polynomial = tune(svm, V58 ~ ., data = new_stan_train, kernel = "polynomial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      degree = c(2, 3, 4, 5)), validation.x = new_stan_test)
```


```{r}
summary(tune.polynomial)
```


```{r}
stan_train_svm <- svm(V58 ~ ., kernel = "polynomial", data=new_stan_train, cost=10, degree = 2)
```

```{r}
plot(stan_train_svm, new_stan_train, formula = V3 ~ V4)
```


```{r}
svm_predict_train_stan <- predict(stan_train_svm,new_stan_train)
```

```{r}
cm_poly_stan_train <- confusionMatrix(as.factor(svm_predict_train_stan), as.factor(new_stan_train$V58), positive = "1")
cm_poly_stan_train
```

The accuracy is 95.47% for the polynomial svm classifier of the standardized train data.


```{r}
svm_predict_test_stan <- predict(stan_train_svm,new_stan_test)
```

```{r}
cm_poly_stan_test <- confusionMatrix(as.factor(svm_predict_test_stan), as.factor(new_stan_test$V58), positive = "1")
cm_poly_stan_test
```

The accuracy is 92.05% for the polynomial svm classifier of the standardized test data.


**Polynomial SVM for the log transformed data**
```{r}
tune.polynomial = tune(svm, V58 ~ ., data = new_log_train, kernel = "polynomial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      degree = c(2, 3, 4, 5)), validation.x = new_log_test)
```


```{r}
summary(tune.polynomial)
```



```{r}
log_train_svm <- svm(V58 ~ ., kernel = "polynomial", data=new_log_train, cost=10, degree = 2)
```

```{r}
plot(log_train_svm, new_log_train, formula = V2 ~ V4)
```


```{r}
svm_predict_train_log <- predict(log_train_svm,new_log_train)
```

```{r}
cm_poly_log_train <- confusionMatrix(as.factor(svm_predict_train_log), as.factor(new_log_train$V58), positive = "1")
cm_poly_log_train
```

The accuracy is 97.72% for the polynomial svm classifier of the log transformed train data.

```{r}
svm_predict_test_log <- predict(log_train_svm,new_log_test)
```

```{r}
cm_poly_log_test <- confusionMatrix(as.factor(svm_predict_test_log), as.factor(new_log_test$V58), positive = "1")
cm_poly_log_test
```

The accuracy is 95.05% for the polynomial svm classifier of the log transformed test data.


**Polynomial SVM of the discretized data**


```{r}
tune.polynomial = tune(svm, V58 ~ ., data = new_I_train, kernel = "polynomial", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10),
                                                                                      degree = c(2, 3, 4, 5)), validation.x = new_I_test)
```


```{r}
summary(tune.polynomial)
```


```{r}
I_train_svm <- svm(V58 ~ ., kernel = "polynomial", data=new_I_train, cost=10, degree = 2)
```

```{r}
plot(I_train_svm, new_I_train, formula = V4 ~ V7)
```


```{r}
svm_predict_train_I <- predict(I_train_svm,new_I_train)
```

```{r}
cm_poly_I_train <- confusionMatrix(as.factor(svm_predict_train_I), as.factor(new_I_train$V58), positive = "1")
cm_poly_I_train
```

The accuracy is 93.87% for the polynomial svm classifier of the discretized train data.

```{r}
svm_predict_test_I <- predict(I_train_svm,new_I_test)
```

```{r}
cm_poly_I_test <- confusionMatrix(as.factor(svm_predict_test_I), as.factor(new_I_test$V58), positive = "1")
cm_poly_I_test
```

The accuracy is 92.24% for the polynomial svm classifier of the discretized test data.


7)
A report of classification errors using different methods and different preprocessed data.


```{r}
cm_linear_train$overall['Accuracy']
cm_linear_test$overall['Accuracy']
cm_linear_stan_train$overall['Accuracy']
cm_linear_stan_test$overall['Accuracy']
cm_linear_log_train$overall['Accuracy']
cm_linear_log_test$overall['Accuracy']
cm_linear_I_train$overall['Accuracy']
cm_linear_I_test$overall['Accuracy']

cm_gaussian_train$overall['Accuracy']
cm_gaussian_test$overall['Accuracy']
cm_gaussian_stan_train$overall['Accuracy']
cm_gaussian_stan_test$overall['Accuracy']
cm_gaussian_log_train$overall['Accuracy']
cm_gaussian_log_test$overall['Accuracy']
cm_gaussian_I_train$overall['Accuracy']
cm_gaussian_I_test$overall['Accuracy']

cm_poly_train$overall['Accuracy']
cm_poly_test$overall['Accuracy']
cm_poly_stan_train$overall['Accuracy']
cm_poly_stan_test$overall['Accuracy']
cm_poly_log_train$overall['Accuracy']
cm_poly_log_test$overall['Accuracy']
cm_poly_I_train$overall['Accuracy']
cm_poly_I_test$overall['Accuracy']

```




```{r}
accuracy.svm.table <- matrix( c(cm_linear_train$overall['Accuracy'], cm_linear_stan_train$overall['Accuracy'], cm_linear_log_train$overall['Accuracy'], cm_linear_I_train$overall['Accuracy'], cm_linear_test$overall['Accuracy'], cm_linear_stan_test$overall['Accuracy'], cm_linear_log_test$overall['Accuracy'], cm_linear_I_test$overall['Accuracy'],  cm_gaussian_train$overall['Accuracy'], cm_gaussian_stan_train$overall['Accuracy'], cm_gaussian_log_train$overall['Accuracy'], cm_gaussian_I_train$overall['Accuracy'], cm_gaussian_test$overall['Accuracy'], cm_gaussian_stan_test$overall['Accuracy'], cm_gaussian_log_test$overall['Accuracy'], cm_gaussian_I_test$overall['Accuracy'], cm_poly_train$overall['Accuracy'], cm_poly_stan_train$overall['Accuracy'], cm_poly_log_train$overall['Accuracy'], cm_poly_I_train$overall['Accuracy'], cm_poly_test$overall['Accuracy'], cm_poly_stan_test$overall['Accuracy'], cm_poly_log_test$overall['Accuracy'], cm_poly_I_test$overall['Accuracy']), ncol=3)

accuracy.svm.table
```


**For the SVM table,**
```{r}
colnames(accuracy.svm.table) <- c("linear", "gaussian", "polynomial")
rownames(accuracy.svm.table) <- c("train", "standardized train", "log train", "I train", "test", "standardized test", "log test", "I test")

accuracy.svm.table
```

**For LDA and QDA table,**
```{r}
colnames(accuracy.da.table) <- c("lda stan", "lda log", "qda stan", "qda log")
rownames(accuracy.da.table) <- c("train", "test")

accuracy.da.table
```



**For Logistic Regression table, **

```{r}
colnames(accuracy.lr.table) <- c("lr original", "lr standardized", "lr log", "lr I")
rownames(accuracy.lr.table) <- c("train", "test")

accuracy.lr.table
```

Note that in all the tables above (SVM, LDA and QDA, and Logistic Regression), the I stands for discretized.


8)
Used single method with properly chosen tuning parameter and a combination of several methods to design a classifier with test error rate as small as possible. 

The log transformation Gaussian SVM classifier has the best test accuracy rate of 96.22% based on the table.

Combine PCA with the Gaussian SVM classisfier for the log transformed to get the smallest test error rate. 

Continue single method tuning with more precise parameters.


Fine tune it even more to achieve a smaller test error.

Original Tune: Cost = 10, gamma = 0.01, accuracy = 96.22%

1st Adjustment: Cost = 9.5, gamma = 0.015, accuracy = 96.41%

2nd Adjustment: Cost = 9.6, gamma = 0.0175, accuracy = 96.61%

3rd Adjustment: Cost = 9.575, gamma = 0.017, accuracy = 96.61%

4th Adjustment: Cost = 9.565, gamma = 0.017, accuracy = 96.61%

5th Adjustment: Cost = 9.56, gamma = 0.0166, accuracy = 96.48%

6th Adjustment: Cost = 9.565, gamma = 0.018, accuracy = 96.22%

7th Adjustment: Cost = 9.565, gamma = 0.0175, accuracy = 96.22%

8th Adjustment: Cost = 9.56,  gamma = 0.0172, accuracy = 96.21%

9th Adjustment: Cost = 9.57,  gamma = 0.0174, accuracy = 96.22%

10th Adjustment: Cost = 9.58,	gamma = 0.0177, accuracy = 96.24%

11th Adjustment: Cost = 9.585, gamma = 0.0179, accuracy = 96.21%

12th Adjustment: Cost = 9.59,  gamma = 0.0175, accuracy = 96.21%

13th Adjustment: Cost = 9.59,  gamma = 0.0171, accuracy = 96.21%

14th Adjustment: Cost = 9.51,  gamma = 0.0171, accuracy = 96.22%

15th Adjustment: Cost = 9.52,  gamma = 0.0172, accuracy = 96.22%	

16th Adjustment: Cost = 9.4	,  gamma = 0.0173, accuracy = 96.20%

17th Adjustment: Cost = 9.4,   gamma = 0.0162, accuracy = 96.20%

18th Adjustment: Cost = 9.3,   gamma = 0.0164, accuracy = 96.22%

19th Adjustment: Cost = 9.3,   gamma = 0.0152, accuracy = 96.22%

20th Adjustment: Cost = 9.3,   gamma = 0.0162, accuracy = 96.22%


Tuned 20 times to make the test error rate smaller. In conclusion, the optimal parameters for the gaussian classifier on the log transformation data is roughly: cost = 9.565, or cost = 9.575, or cost = 9.56, gamma = 0.017, or gamma = 0.0175 for an accuracy of 96.61%, an improvement of 0.4% compare to the original tuning parameter.

```{r}
tune.gaussian = tune(svm, V58 ~ ., data = new_log_train, kernel = "radial", ranges = list(cost=c(9.3, 9.31, 9.32, 9.33, 9.34), gamma = c(0.0162, 0.0163, 0.0164, 0.0165, 0.0166)), validation.x = new_log_test )
```


```{r}
summary(tune.gaussian)
```

```{r}
svm_predict_test_log <- predict(log_train_svm,new_log_test)
```

```{r}
cm_gaussian_log_test <- confusionMatrix(as.factor(svm_predict_test_log), as.factor(new_log_test$V58), positive = "1")
cm_gaussian_log_test
```
